<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>STA 3311 Sports Analytics II - 14&nbsp; Dimensionality Reduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./15_SVM.html" rel="next">
<link href="./13_clustering.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="webex.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./14_dimension.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Intro to Data Manipulation with <code>dplyr</code></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Stringr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">String, Dates, and Joins</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Tidymodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to Tidymodels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Linear Regression with Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Logistic Regression with Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_Mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Mixed Effects Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Obtaining Sport Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_Web.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Web Scraping with Rvest</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_Random.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Random Forests</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_Spatial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Visualization of Player Tracking Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_knn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">K-Nearest Neighbors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_dimension.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_DBSCAN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">DBSCAN</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">14.1</span> Introduction</a></li>
  <li>
<a href="#reasons-for-dimensionality-reduction" id="toc-reasons-for-dimensionality-reduction" class="nav-link" data-scroll-target="#reasons-for-dimensionality-reduction"><span class="header-section-number">14.2</span> Reasons for Dimensionality Reduction</a>
  <ul class="collapse">
<li><a href="#curse-of-dimensionality" id="toc-curse-of-dimensionality" class="nav-link" data-scroll-target="#curse-of-dimensionality"><span class="header-section-number">14.2.1</span> <strong>Curse of Dimensionality</strong>:</a></li>
  </ul>
</li>
  <li>
<a href="#techniques-of-dimensionality-reduction" id="toc-techniques-of-dimensionality-reduction" class="nav-link" data-scroll-target="#techniques-of-dimensionality-reduction"><span class="header-section-number">14.3</span> Techniques of Dimensionality Reduction</a>
  <ul class="collapse">
<li><a href="#feature-selection" id="toc-feature-selection" class="nav-link" data-scroll-target="#feature-selection"><span class="header-section-number">14.3.1</span> Feature Selection</a></li>
  </ul>
</li>
  <li><a href="#feature-extraction" id="toc-feature-extraction" class="nav-link" data-scroll-target="#feature-extraction"><span class="header-section-number">14.4</span> Feature Extraction</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><blockquote class="blockquote">
<p>“Everyone has a plan ’till they get punched in the mouth.” - Mike Tyson</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="pics/tyson.png" class="img-fluid figure-img" width="200"></p>
<figcaption class="figure-caption">Mike Tyson bites Evander Holyfield’s ear in their heavyweight championship fight on June 28, 1997. This was the first, and worst, of two bites that took aobut a one-inch piece of cartilage from Holyfield’s ear. After biting his other ear a few minutes later, Tyson was disqualified.</figcaption></figure>
</div>
<section id="introduction" class="level2" data-number="14.1"><h2 data-number="14.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">14.1</span> Introduction</h2>
<p>In the realm of statistics and data science, the ability to effectively analyze and draw insights from data is paramount. As we venture into the era of big data, we encounter datasets of increasing complexity and size. These datasets often comprise a vast number of variables, a situation described as <strong>high dimensionality</strong>. Understanding the concept of dimensionality reduction is essential, not just as an abstract mathematical idea but as a practical tool for making sense of complex data.</p>
<p>Dimensionality reduction sits at the heart of sports analytics, serving as a bridge between raw data and actionable insights. It addresses several critical challenges in data analysis, including the curse of dimensionality, noise in the dataset, and the difficulties involved in visualizing multidimensional data. By simplifying the data without significant loss of information, dimensionality reduction techniques enable us to build models that are not only more efficient but also more interpretable.</p>
<p>The study of dimensionality reduction offers a glimpse into the interdisciplinary nature of data science, where statistics, computer science, and domain expertise converge. This area highlights the importance of understanding both the theoretical foundations and the practical applications of statistical methods. While the mathematical underpinnings, such as linear algebra, are crucial, the focus here is on grasping the conceptual framework and the impact of dimensionality reduction on data analysis.</p>
<p>The introduction to dimensionality reduction begins with the rationale behind it. As datasets grow in size and complexity, the limitations of traditional analytical tools become apparent. The curse of dimensionality, a phenomenon where the data space expands so much that our data becomes sparse, affects not only the computational feasibility of models but also their performance. Reducing the number of input variables helps mitigate these issues, making models simpler, faster, and more generalizable.</p>
<p>Moreover, in a practical setting, the reduction of dimensionality can be pivotal for noise reduction and visualization. By filtering out irrelevant or redundant features, we improve the model’s accuracy and reliability. Similarly, the transformation of high-dimensional data into a more manageable form allows for effective visualization, which is indispensable for data exploration and hypothesis generation.</p>
<p>Dimensionality reduction techniques, categorized into feature selection and feature extraction, offer a toolkit for addressing these challenges. Feature selection methods focus on identifying the most relevant features for the models. On the other hand, feature extraction techniques like Principal Component Analysis (PCA), transform the original features into a new set of variables that better capture the underlying structure of the data.</p>
</section><section id="reasons-for-dimensionality-reduction" class="level2" data-number="14.2"><h2 data-number="14.2" class="anchored" data-anchor-id="reasons-for-dimensionality-reduction">
<span class="header-section-number">14.2</span> Reasons for Dimensionality Reduction</h2>
<section id="curse-of-dimensionality" class="level3" data-number="14.2.1"><h3 data-number="14.2.1" class="anchored" data-anchor-id="curse-of-dimensionality">
<span class="header-section-number">14.2.1</span> <strong>Curse of Dimensionality</strong>:</h3>
<p>The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces (often with hundreds or thousands of dimensions) that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience. It’s essential in understanding how dimensionality affects data analysis, leading to specific issues like data sparsity and increased computational complexity.</p>
<section id="understanding-the-curse-of-dimensionality" class="level4"><h4 class="anchored" data-anchor-id="understanding-the-curse-of-dimensionality"><strong>Understanding the Curse of Dimensionality</strong></h4>
<p>When the dimensionality increases, the volume of the space increases so rapidly that the available data become sparse. This sparsity is problematic for any method that requires statistical significance. In order to obtain a statistically reliable result, the amount of data needed to support the result often grows exponentially with the dimensionality. Additionally, high-dimensional datasets are often accompanied by increased computational complexity and a greater chance of overfitting, making models less generalizable to new data.</p>
</section><section id="example-using-the-batting-dataset" class="level4"><h4 class="anchored" data-anchor-id="example-using-the-batting-dataset"><strong>Example using the <code>Batting</code> dataset</strong></h4>
<p>The <code>Batting</code> dataset in the <code>Lahman</code> library consists of batting statistics for MLB players.</p>
<p>Loading and Exploring the Data</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://CRAN.R-project.org/package=Lahman">Lahman</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggobi.github.io/ggally/">GGally</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"Batting"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Below is a scatterplot matrix of the pairs of 9 of the quantitative features for the Texas Rangers during the 2004 season.</p>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Batting</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">yearID</span><span class="op">==</span><span class="fl">2004</span> <span class="op">&amp;</span> <span class="va">teamID</span><span class="op">==</span><span class="st">"TEX"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">R</span><span class="op">:</span><span class="va">BB</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggobi.github.io/ggally/reference/ggpairs.html">ggpairs</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>With so many variables, it becomes cumbersome to visualize the relationships between the variables. The above scatterplot matrix shows the scatterplots of the 36 pairs of variables when you have nine features. It becomes difficult to examine all of these scatterplots. These plots also do not show any relationships between three variables at a time, and so forth.</p>
<p>In addition to visualization, the curse of dimenstionality also implies the sparseness of the data when we have more variables.</p>
<p>Let’s first examine the variable <code>R</code>. Below is a dotplot for this variable.</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Batting</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">yearID</span><span class="op">==</span><span class="fl">2004</span> <span class="op">&amp;</span> <span class="va">teamID</span><span class="op">==</span><span class="st">"TEX"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">R</span>, y <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">""</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span></span>
<span>    axis.ticks.y<span class="op">=</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_blank</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>    axis.text.y<span class="op">=</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_blank</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>Note that the min value of <code>R</code> is 0 and the max value is 114. There are 53 observations so we can think of the data for this variable as 53 pieces of information in that variable’s dimension (the <span class="math inline">\(x\)</span> dimenstion on the plot above). Let’s calculate the ratio of information to the dimensional space:</p>
<p><span class="math display">\[
\frac{53}{114-0} = 0.4649
\]</span></p>
<p>Let’s now examine another variable along with <code>R</code>. Below is the scatterplot of <code>R</code> and <code>RBI</code></p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">Batting</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">yearID</span><span class="op">==</span><span class="fl">2004</span> <span class="op">&amp;</span> <span class="va">teamID</span><span class="op">==</span><span class="st">"TEX"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">R</span>, y <span class="op">=</span> <span class="va">RBI</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>For <code>RBI</code>, the range of values are min = 0 and max = 112. The total dimensional space that these two variables take is <span class="math display">\[
\begin{align*}
\text{dimensional space for R}\times\text{dimensional space for RBI} &amp;= 114 \times 112\\
&amp;= 12768
\end{align*}
\]</span></p>
<p>We still only have 25 observations. The 53 pieces of information that we have in this two-dimensional space gives us the ratio <span class="math display">\[
\frac{53}{12768} = 0.0042
\]</span></p>
<p>So in two-dimensional space, the amount of data we have is a much lower ratio of the space than when we had in only one dimension.</p>
<p>Let’s now add in a third variable <code>BB</code>. Note that the dimensional space for <code>BB</code> is min = 0 and max = 75. The size of the total dimensional space is <span class="math display">\[
\begin{align*}
\text{dim. space for R}\times\text{dim. space for RBI}\times\text{dim. space for BB} &amp;= 114 \times 112 \times 75\\
&amp;= 957600
\end{align*}
\]</span></p>
<p>Again, we still only have 53 observations. So our 53 pieces of information only take up a ratio of <span class="math display">\[
\frac{53}{957600}=0.00006
\]</span> of the 3-dimensional space. The more variables we have, the higher the dimensional space our observations are in. The ratio of our observations to the area of the dimensional space will continue to decrease. Thus, the amount of data available in that high dimension is sparse. This is the curse of dimensionality.</p>
</section></section></section><section id="techniques-of-dimensionality-reduction" class="level2" data-number="14.3"><h2 data-number="14.3" class="anchored" data-anchor-id="techniques-of-dimensionality-reduction">
<span class="header-section-number">14.3</span> Techniques of Dimensionality Reduction</h2>
<p>There are several techniques for reducing the dimensionality of data, broadly categorized into <strong>Feature Selection</strong> and <strong>Feature Extraction</strong>.</p>
<section id="feature-selection" class="level3" data-number="14.3.1"><h3 data-number="14.3.1" class="anchored" data-anchor-id="feature-selection">
<span class="header-section-number">14.3.1</span> Feature Selection</h3>
<p>Feature selection involves selecting a subset of the most relevant features for use in model construction. There are three main types of feature selection methods:</p>
<section id="filter-methods" class="level4"><h4 class="anchored" data-anchor-id="filter-methods">
<strong>Filter Methods</strong>:</h4>
<p>Filter Methods are among the first steps you can take in preprocessing your data for machine learning models. They are computationally less expensive than Wrapper and Embedded Methods because they do not involve training models as part of the feature selection process. Instead, they rely on general characteristics of the data, such as correlation coefficients, Chi-square tests, and mutual information.</p>
<p><strong>Advantages:</strong></p>
<ol type="1">
<li>
<strong>Speed:</strong> They are fast and scalable to high-dimensional datasets because they evaluate features in isolation from the model.</li>
<li>
<strong>Simplicity:</strong> These methods are straightforward to understand and implement.</li>
<li>
<strong>Model Agnostic:</strong> They can be applied regardless of the choice of machine learning algorithm.</li>
</ol>
<p><strong>Disadvantages:</strong></p>
<ol type="1">
<li><p><strong>Less Accurate:</strong> They might not capture feature interactions well because they evaluate each feature independently.</p></li>
<li><p><strong>No Model Context:</strong> They do not consider how features will interact when combined in a model, potentially overlooking combinations that would improve model performance.</p></li>
</ol>
<p><strong>Common Techniques in Filter Methods</strong></p>
<ol type="1">
<li><p><strong>Correlation Coefficient:</strong> This measures the linear relationship between two variables. Features with very low correlation to the target variable can be removed.</p></li>
<li><p><strong>Chi-Square Test:</strong> This statistical test is used to determine if there is a significant association between two categorical variables. It can be used to select relevant features for classification problems.</p></li>
<li><p><strong>Mutual Information:</strong> This measures the amount of information one can obtain from one variable through another. A higher value means more information shared, making it useful for feature selection.</p></li>
<li><p><strong>Variance Threshold:</strong> This method removes all features whose variance doesn’t meet some threshold. Since variables with a low variance are less likely to affect the target variable, they can be considered for removal.</p></li>
</ol>
<p><strong>Application of Filter Methods</strong></p>
<p>Filter Methods are widely used at the beginning stages of the feature selection process, especially when dealing with very high-dimensional data. They help in narrowing down the feature set to a more manageable size, which can then be further refined using more sophisticated techniques like Wrapper and Embedded Methods.</p>
<p><strong>Example: Batting data</strong></p>
<p>Suppose <code>R</code> is the response variable. We can examine the correlation between <code>R</code> and all other features.</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">correlation_matrix</span> <span class="op">&lt;-</span> <span class="va">Batting</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">yearID</span><span class="op">==</span><span class="fl">2004</span> <span class="op">&amp;</span> <span class="va">teamID</span><span class="op">==</span><span class="st">"TEX"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">R</span><span class="op">:</span><span class="va">BB</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">correlations</span> <span class="op">&lt;-</span> <span class="va">correlation_matrix</span><span class="op">[</span><span class="st">'R'</span>, <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">correlations</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        R         H       X2B       X3B        HR       RBI        SB        CS 
1.0000000 0.9886300 0.9737135 0.8520469 0.9385321 0.9828114 0.6668248 0.6036253 
       BB 
0.9459635 </code></pre>
</div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Visualize the correlations for better understanding</span></span>
<span><span class="va">correlations</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tibble.tidyverse.org/reference/rownames.html">rownames_to_column</a></span><span class="op">(</span><span class="st">"Feature"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/reorder.factor.html">reorder</a></span><span class="op">(</span><span class="va">Feature</span>, <span class="op">-</span><span class="va">value</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">value</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span>stat <span class="op">=</span> <span class="st">"identity"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Correlation with R"</span>, </span>
<span>       x <span class="op">=</span> <span class="st">"Feature"</span>, </span>
<span>       title <span class="op">=</span> <span class="st">"Feature Correlation with R"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="576"></p>
</div>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Select features based on a correlation threshold, for example, features with absolute correlation &gt; 0.7</span></span>
<span><span class="va">relevant_features</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">correlations</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">correlations</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0.7</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">relevant_features</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "R"   "H"   "X2B" "X3B" "HR"  "RBI" "BB" </code></pre>
</div>
</div>
<p>While Filter Methods are an efficient way to reduce dimensionality, especially in the preliminary stages of model development, they should be part of a broader feature selection strategy that may include more sophisticated methods. Combining various methods thoughtfully can lead to the development of more accurate and robust predictive models.</p>
</section><section id="wrapper-methods" class="level4"><h4 class="anchored" data-anchor-id="wrapper-methods">
<strong>Wrapper Methods</strong>:</h4>
<p>Wrapper methods select features based on the performance of a predictive model, where features are added or removed according to their contribution to model accuracy. This approach differs from filter methods, which rely on the general characteristics of the data, and embedded methods, which perform feature selection as part of the model training process.</p>
<p><strong>Example: Applying Wrapper Methods to the Batting Dataset</strong></p>
<p>Assuming we are interested in modeling <code>R</code> based on the other batting statistics, we could use a wrapper method to select the most relevant features for predicting runs. This process involves iteratively adding or removing features based on their impact on the model’s predictive accuracy.</p>
<p>We use a stepwise regression approach, which considers both addition and removal of features based on their statistical significance to the model’s performance. The <code>stepAIC</code> function from the <code>MASS</code> package in R can perform this operation, aiming to minimize the Akaike Information Criterion (AIC) for model selection:</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">dat</span> <span class="op">=</span> <span class="va">Batting</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">yearID</span><span class="op">==</span><span class="fl">2004</span> <span class="op">&amp;</span> <span class="va">teamID</span><span class="op">==</span><span class="st">"TEX"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">R</span><span class="op">:</span><span class="va">BB</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">R</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">dat</span><span class="op">)</span></span>
<span><span class="va">stepModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/stepAIC.html">stepAIC</a></span><span class="op">(</span><span class="va">fit</span>, direction<span class="op">=</span><span class="st">"both"</span>, trace <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=70.36
R ~ H + X2B + X3B + HR + RBI + SB + CS + BB

       Df Sum of Sq    RSS     AIC
- SB    1     0.546 142.90  68.568
- CS    1     0.987 143.34  68.731
&lt;none&gt;              142.35  70.365
- H     1     7.925 150.28  71.236
- HR    1    22.283 164.63  76.072
- X2B   1    32.174 174.53  79.165
- RBI   1   101.383 243.73  96.867
- X3B   1   106.221 248.57  97.909
- BB    1   194.869 337.22 114.074

Step:  AIC=68.57
R ~ H + X2B + X3B + HR + RBI + CS + BB

       Df Sum of Sq    RSS     AIC
- CS    1      0.55 143.44  66.769
&lt;none&gt;              142.90  68.568
+ SB    1      0.55 142.35  70.365
- H     1     28.94 171.84  76.341
- HR    1     49.14 192.04  82.232
- X2B   1    147.27 290.17 104.109
- X3B   1    168.83 311.73 107.908
- RBI   1    179.33 322.23 109.664
- BB    1    341.15 484.05 131.230

Step:  AIC=66.77
R ~ H + X2B + X3B + HR + RBI + BB

       Df Sum of Sq    RSS     AIC
&lt;none&gt;              143.44  66.769
+ CS    1      0.55 142.90  68.568
+ SB    1      0.10 143.34  68.731
- H     1     32.41 175.86  75.567
- HR    1     61.07 204.51  83.567
- X2B   1    146.73 290.18 102.110
- RBI   1    181.01 324.45 108.027
- X3B   1    199.91 343.36 111.030
- BB    1    377.96 521.40 133.170</code></pre>
</div>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">stepModel</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = R ~ H + X2B + X3B + HR + RBI + BB, data = dat)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5557  0.0618  0.0618  0.5715  3.8356 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.06181    0.28073  -0.220  0.82671    
H           -0.20661    0.06409  -3.224  0.00233 ** 
X2B          0.90354    0.13172   6.860 1.48e-08 ***
X3B          5.17137    0.64587   8.007 2.89e-10 ***
HR          -0.84258    0.19040  -4.425 5.87e-05 ***
RBI          0.79409    0.10423   7.619 1.08e-09 ***
BB           0.48002    0.04360  11.009 1.75e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.766 on 46 degrees of freedom
Multiple R-squared:  0.997, Adjusted R-squared:  0.9966 
F-statistic:  2570 on 6 and 46 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>This code starts with a model that includes all available features (except <code>R</code>, which is our target variable) and then iteratively adds or removes features to find a combination that offers the best balance between model complexity and predictive power, as measured by the AIC.</p>
<p><strong>Evaluating the Selected Features</strong></p>
<p>The output of <code>stepAIC</code> will indicate which features have been selected as predictors for Runs. These features are deemed by the stepwise regression process as having significant predictive power for <code>R</code>, after considering the potential for overfitting (through AIC minimization).</p>
<p>This approach allows for an automated and data-driven selection of features, which can be especially useful when dealing with datasets with many variables. By focusing on the subset of features that contribute most to prediction accuracy, wrapper methods can help create more efficient and interpretable models.</p>
</section><section id="embedded-methods" class="level4"><h4 class="anchored" data-anchor-id="embedded-methods">
<strong>Embedded Methods</strong>:</h4>
<p>Embedded methods are particularly useful as they perform feature selection while the model is being trained, which can lead to a more optimal set of features for the prediction task at hand. Regularization methods like LASSO (Least Absolute Shrinkage and Selection Operator) are common examples of embedded methods because they both train the model and select features by penalizing the absolute size of the regression coefficients.</p>
<p>Embedded methods combine the qualities of filter and wrapper methods by performing feature selection as part of the model training process. This approach can lead to more accurate and efficient models because it considers the interaction between features and the model. One key advantage of embedded methods is their ability to capture complex interactions between features, which might be missed by filter methods.</p>
<p><strong>Example: Batting Data</strong></p>
<p>In this example, we’ll use the Batting data to predict Runs. We’ll apply LASSO regression, an embedded method, using the <code>tidymodels</code> framework.</p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll use a LASSO regression model, which is suited for datasets with potentially correlated predictors and can help in feature selection by shrinking some coefficients to zero.</p>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">MultBiplotR</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">lasso_spec</span> <span class="op">&lt;-</span> <span class="fu">linear_reg</span><span class="op">(</span>penalty <span class="op">=</span> <span class="fl">0.1</span>, mixture <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>  <span class="op">|&gt;</span> </span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"glmnet"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">recipe</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">R</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span>  <span class="op">|&gt;</span> </span>
<span>  <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_numeric_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">prep</span><span class="op">(</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">dat_baked</span> <span class="op">=</span> <span class="va">recipe</span> <span class="op">|&gt;</span> <span class="fu">bake</span><span class="op">(</span>new_data <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span>
<span>  </span>
<span><span class="va">lasso_fit</span> <span class="op">&lt;-</span> <span class="va">lasso_spec</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">fit</span><span class="op">(</span><span class="va">R</span><span class="op">~</span><span class="va">.</span>, data <span class="op">=</span> <span class="va">dat_baked</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lasso_fit</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">tidy</span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 9 × 3
  term        estimate penalty
  &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept)   16.2       0.1
2 H              0         0.1
3 X2B            6.68      0.1
4 X3B            6.05      0.1
5 HR             0         0.1
6 RBI           10.7       0.1
7 SB             0         0.1
8 CS             0.185     0.1
9 BB             8.31      0.1</code></pre>
</div>
</div>
<p>This process will provide us with an understanding of which features are most predictive of Runs, leveraging the embedded method’s ability to perform feature selection in conjunction with model training. By focusing on the subset of features that contribute most to prediction accuracy, we can create more efficient and interpretable models.</p>
</section></section></section><section id="feature-extraction" class="level2" data-number="14.4"><h2 data-number="14.4" class="anchored" data-anchor-id="feature-extraction">
<span class="header-section-number">14.4</span> Feature Extraction</h2>
<p>Feature extraction transforms the data in the high-dimensional space to a space of fewer dimensions. The data transformation may be linear or nonlinear, with the transformed features being combinations of the original features. The most common feature extraction techniques include:</p>
<section id="principal-component-analysis-pca" class="level4"><h4 class="anchored" data-anchor-id="principal-component-analysis-pca"><strong>Principal Component Analysis (PCA):</strong></h4>
<ul>
<li>
<strong>Purpose:</strong> PCA reduces dimensionality by transforming the original variables into a new set of uncorrelated variables, called principal components, which are ordered by the amount of original variance they capture. The first principal component captures the most variance, the second captures the second most, and so on.</li>
</ul>
<p>Suppose we had two variables: height and hair color (some measure of darkness of hair) for a Native American tribe. Below is a scatterplot of the two variables:</p>
<p><img src="pics/heights.png" class="img-fluid"></p>
<p>It’s evident that in this tribe, the variation in hair color among individuals is minimal compared to the range of their heights. Therefore, height emerges as a more significant characteristic than hair color. Consequently, by incorporating only the height of individuals from this tribe as a feature in the dataset, we can preserve the majority of the relevant information.</p>
<p>Most situation do not result in a scatterplot as we see above. Instead, you may see a situation as below.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>Instead of <span class="math inline">\(X\)</span> or <span class="math inline">\(y\)</span> having small variability, we can imagine a line drawn through the points and the variability of the points about that line is small.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>If we rotate the plot so that the blue line is now the horizontal axis, the new axes can then be examined and we can use ony the axis that has the larger variability. These new axes are called the Principal Components.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>In this example, the first principal component (PCA1) has large variability. the second principal component (PCA2) has small variability. So if we use only PCA1 as our feature, then we only lose a small amount of information in how the data varies when we do not select PCA2.</p>
<p>PCA starts by calculating the covariance matrix of the data to understand how variables are related. It then computes the eigenvectors and eigenvalues of this covariance matrix. Eigenvectors determine the directions of the new space, and eigenvalues determine their magnitude. In essence, the eigenvectors with the highest eigenvalues are selected to form the new set of variables.</p>
</section><section id="linear-discriminant-analysis-lda" class="level4"><h4 class="anchored" data-anchor-id="linear-discriminant-analysis-lda"><strong>Linear Discriminant Analysis (LDA):</strong></h4>
<ul>
<li>
<strong>Purpose:</strong> LDA is a supervised dimensionality reduction technique used to find the linear combinations of features that best separate two or more classes of objects or events. The goal is to project the features in higher-dimensional space onto a lower-dimensional space with good class-separability in order to avoid overfitting (“curse of dimensionality”) and also reduce computational costs.</li>
<li>
<strong>How it Works:</strong> LDA computes the directions (“linear discriminants”) that will represent the axes that maximize the separation between multiple classes. It takes the mean and variance of each class into account and seeks to reduce variance within each class while maximizing variance between the classes.</li>
<li>
<strong>Applications:</strong> LDA is particularly useful in the preprocessing steps for pattern classification and machine learning applications. Its application spans across various fields including face recognition, medical diagnosis, and any domain requiring classification tasks.</li>
</ul></section><section id="t-distributed-stochastic-neighbor-embedding-t-sne" class="level4"><h4 class="anchored" data-anchor-id="t-distributed-stochastic-neighbor-embedding-t-sne"><strong>t-Distributed Stochastic Neighbor Embedding (t-SNE):</strong></h4>
<ul>
<li>
<strong>Purpose:</strong> t-SNE is a nonlinear technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. It converts similarities between data points to joint probabilities and tries to minimize the divergence between these joint probabilities in the high-dimensional and low-dimensional space.</li>
<li>
<strong>How it Works:</strong> t-SNE starts by calculating the probability that pairs of datapoints in the high-dimensional space are similar, then uses a gradient descent method to minimize the difference between this probability distribution and a similar distribution in the low-dimensional space.</li>
<li>
<strong>Applications:</strong> Because of its ability to preserve local structures and resolve clusters in a small area of the map, t-SNE is highly favored for visualizing high-dimensional data such as genetic data, image data, or text data.</li>
</ul>
<p><strong>Considerations When Choosing a Feature Extraction Technique:</strong></p>
<ul>
<li>The <strong>nature of the dataset</strong>: Is it linear or nonlinear? PCA and LDA assume linear relationships between variables, while t-SNE does not.</li>
<li>
<strong>Supervised vs.&nbsp;Unsupervised learning</strong>: PCA and t-SNE are unsupervised methods (they do not require labeled data), whereas LDA is supervised (requires labeled data).</li>
<li>
<strong>Goal of dimensionality reduction</strong>: Is the goal to improve visualization (t-SNE), to prepare for a classification task (LDA), or to reduce feature space while retaining variance (PCA)?</li>
<li>
<strong>Computational resources and dataset size</strong>: PCA and LDA are relatively more computationally efficient than t-SNE, especially for very large datasets.</li>
</ul></section><section id="pca-example-batting-data" class="level4"><h4 class="anchored" data-anchor-id="pca-example-batting-data">PCA Example: Batting Data</h4>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># PCA with tidymodels</span></span>
<span><span class="va">pca_recipe</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="op">~</span><span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="co">#Get enough PCs to get 95% of variance</span></span>
<span>  <span class="fu">step_pca</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span>, threshold <span class="op">=</span> <span class="fl">.95</span><span class="op">)</span> <span class="op">|&gt;</span>  </span>
<span>  <span class="fu">prep</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Extract the PCA results</span></span>
<span><span class="va">pca_results</span> <span class="op">&lt;-</span> <span class="fu">bake</span><span class="op">(</span><span class="va">pca_recipe</span>, new_data <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># View the results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">pca_results</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 53 × 3
      PC1     PC2      PC3
    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;
 1 -1.25  -0.0800 -0.0304 
 2 -0.696  0.283  -0.341  
 3 -1.44  -0.0152 -0.0698 
 4 -1.36  -0.0432  0.00207
 5 -1.44  -0.0152 -0.0698 
 6  2.45  -1.19    0.357  
 7 -1.43  -0.0193 -0.0694 
 8 -1.44  -0.0152 -0.0698 
 9  7.22  -2.23    1.25   
10 -1.44  -0.0152 -0.0698 
# ℹ 43 more rows</code></pre>
</div>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu">tidy</span><span class="op">(</span><span class="va">pca_recipe</span>, number <span class="op">=</span> <span class="fl">2</span>, type <span class="op">=</span> <span class="st">"variance"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">terms</span> <span class="op">==</span> <span class="st">"cumulative percent variance"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 9 × 4
  terms                       value component id       
  &lt;chr&gt;                       &lt;dbl&gt;     &lt;int&gt; &lt;chr&gt;    
1 cumulative percent variance  81.7         1 pca_zPW5q
2 cumulative percent variance  92.9         2 pca_zPW5q
3 cumulative percent variance  97.2         3 pca_zPW5q
4 cumulative percent variance  98.8         4 pca_zPW5q
5 cumulative percent variance  99.6         5 pca_zPW5q
6 cumulative percent variance  99.9         6 pca_zPW5q
7 cumulative percent variance 100.          7 pca_zPW5q
8 cumulative percent variance 100.          8 pca_zPW5q
9 cumulative percent variance 100           9 pca_zPW5q</code></pre>
</div>
</div>
<p>We see that only three principal components are needed to capture 95% of the variability present in the nine predictor variables.</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Visualize PCA results</span></span>
<span><span class="va">pca_results</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">PC1</span>, y <span class="op">=</span> <span class="va">PC2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Principal Component 1"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Principal Component 2"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="14_dimension_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="576"></p>
</div>
</div>


</section></section></main><!-- /main --><script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./13_clustering.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Clustering</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./15_SVM.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">STA 3311</div>
  </div>
</footer>


</body></html>