<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>STA 3311 Sports Analytics II - 17&nbsp; Multi-Layer Perceptron</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./18_Fitting.html" rel="next">
<link href="./16_DBSCAN.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="webex.css">
</head>
<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./17_MLP.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Multi-Layer Perceptron</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./"></a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Intro to Data Manipulation with <code>dplyr</code></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_Stringr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">String, Dates, and Joins</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Tidymodels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to Tidymodels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Linear Regression with Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Logistic Regression with Regularization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_Mixed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Mixed Effects Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_Data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Obtaining Sport Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_Web.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Web Scraping with Rvest</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_Random.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Random Forests</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_Spatial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Visualization of Player Tracking Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_knn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">K-Nearest Neighbors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Clustering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_dimension.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15_SVM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_DBSCAN.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">DBSCAN</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./17_MLP.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Multi-Layer Perceptron</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18_Fitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Fitting and Overfitting</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_Rankings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Intro to Rankings</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li>
<a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">17.1</span> Introduction</a>
  <ul class="collapse">
<li><a href="#threshold-logic-unit" id="toc-threshold-logic-unit" class="nav-link" data-scroll-target="#threshold-logic-unit"><span class="header-section-number">17.1.1</span> Threshold Logic Unit</a></li>
  </ul>
</li>
  <li><a href="#the-perceptron" id="toc-the-perceptron" class="nav-link" data-scroll-target="#the-perceptron"><span class="header-section-number">17.2</span> The Perceptron</a></li>
  <li><a href="#example-iris-data" id="toc-example-iris-data" class="nav-link" data-scroll-target="#example-iris-data"><span class="header-section-number">17.3</span> Example: Iris data</a></li>
  <li><a href="#multilayer-perceptron" id="toc-multilayer-perceptron" class="nav-link" data-scroll-target="#multilayer-perceptron"><span class="header-section-number">17.4</span> Multilayer Perceptron</a></li>
  <li>
<a href="#gradient-descent-and-backpropagation" id="toc-gradient-descent-and-backpropagation" class="nav-link" data-scroll-target="#gradient-descent-and-backpropagation"><span class="header-section-number">17.5</span> Gradient Descent and Backpropagation</a>
  <ul class="collapse">
<li><a href="#backpropagation" id="toc-backpropagation" class="nav-link" data-scroll-target="#backpropagation"><span class="header-section-number">17.5.1</span> Backpropagation</a></li>
  </ul>
</li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions"><span class="header-section-number">17.6</span> Activation Functions</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title">
<span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Multi-Layer Perceptron</span>
</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><blockquote class="blockquote">
<p>“Tuck Rule game, against the Raiders, might have been a fumble.” - Tom Brady</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="pics/brady.jpg" class="img-fluid figure-img" width="200"></p>
<figcaption class="figure-caption">On January 19, 2002, the Oakland Raiders were leading the New England Patriots with 1:43 left to play in the game. Patriots QB Tom Brady dropped backed to pass but had the ball chopped out of his hands by Raiders CB Charles Woodson causing what appeared to be a fumble. The Raiders recovered the fumble which would seal their victory. However, the referees stated that Brady’s arm was in a forward motion and ruled the play as an incomplete pass. The Patriots would end up winning the game in OT in what become known as the “Tuck Rule Game.”</figcaption></figure>
</div>
<section id="introduction" class="level2" data-number="17.1"><h2 data-number="17.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">17.1</span> Introduction</h2>
<p>The concept of human flight was inspired by observing the soaring of eagles, the sticky nature of gecko feet led to the invention of adhesive tapes, and myriad other breakthroughs have been sparked by the wonders of the natural world. It follows, then, that the intricate workings of the human brain could serve as the model for devising intelligent machinery. This line of thought led to the creation of artificial neural networks (ANNs), machine learning frameworks modeled on the intricate web of biological neurons in our brains. Yet, in the same way that modern aircraft do not replicate the precise movements of an eagle’s wings, ANNs have developed in ways that significantly depart from their biological counterparts.</p>
<p>ANNs are fundamental to deep learning, offering versatility, power, and scalability. They tackle complex machine learning challenges, from image classification (like Google Images) and voice recognition (such as Apple’s Siri) to recommending videos on YouTube.</p>
<p>But before we dive into the present and future of ANNs, let’s take a step back and trace their origins and evolution.</p>
<section id="history-of-anns" class="level4"><h4 class="anchored" data-anchor-id="history-of-anns">History of ANNs</h4>
<p>Artificial Neural Networks (ANNs) have a surprisingly long history, dating back to their inception in 1943 by neurophysiologist Warren McCulloch and mathematician Walter Pitts. Their groundbreaking paper, “A Logical Calculus of Ideas Immanent in Nervous Activity,” introduced the first computational model suggesting how neurons in the brain might work together to process complex calculations using propositional logic, marking the debut of artificial neural network architecture. Over time, numerous other architectures have emerged.</p>
<p>Initially, ANNs fostered optimism about the imminent advent of truly intelligent machines. However, by the 1960s, it became evident that such expectations were premature, leading to a reduction in funding and a period of dormancy for ANNs. The early 1980s saw a resurgence in interest thanks to new architectures and improved training techniques. Yet, progress was gradual, and by the 1990s, other machine learning methods, like Support Vector Machines, seemed to offer more promising results and theoretical underpinnings, causing neural network research to once again pause.</p>
<p>Today, we’re experiencing a renewed fascination with ANNs, driven by several factors suggesting this wave might have a more lasting impact:</p>
<ul>
<li>The abundance of data available for training, with ANNs often surpassing other techniques on complex tasks.</li>
<li>A significant increase in computational power, partially credited to Moore’s law and the demand for advanced GPU cards fueled by the gaming industry. Cloud platforms also play a crucial role in democratizing access to this computational power.</li>
<li>Enhancements in training algorithms, which, despite being minor, have significantly improved performance.</li>
<li>Some anticipated theoretical limitations of ANNs have proven manageable in practice, such as the concern about training algorithms getting stuck in local optima.</li>
<li>The virtuous cycle of funding and progress, where innovative ANN-based products generate headlines, attracting more interest and investment, which in turn leads to further advancements and even more groundbreaking applications.</li>
</ul>
<p>Before exploring artificial neurons, let’s quickly overview a biological neuron. Typically found in animal brains, a neuron consists of a cell body with a nucleus, several dendrites, and a long axon extending significantly beyond the cell body to connect with other neurons via synapses at its branches, known as telodendria. Neurons communicate by transmitting electrical signals, triggering the release of neurotransmitters, which then activate other neurons based on the type of neurotransmitter.</p>
<p>Despite their simple individual function, neurons form extensive networks capable of complex processing, much like ants build a sophisticated anthill. The architecture of these networks, particularly in the brain’s cerebral cortex where neurons are arranged in layers, remains a key focus of scientific study.</p>
<p>McCulloch and Pitts’s model proposed a basic form of the biological neuron, later termed an artificial neuron, which processes binary inputs and outputs. Their model demonstrated that a network of such neurons could perform any logical calculation. Illustrations of these networks show basic logical functions like identity, AND, OR, and more complex propositions, indicating the foundational capabilities of these early neural networks.</p>
</section><section id="threshold-logic-unit" class="level3" data-number="17.1.1"><h3 data-number="17.1.1" class="anchored" data-anchor-id="threshold-logic-unit">
<span class="header-section-number">17.1.1</span> Threshold Logic Unit</h3>
<p>Introduced by Frank Rosenblatt in 1957, the Perceptron represents one of the most fundamental types of artificial neural network architectures. It operates using a special form of artificial neuron known as a threshold logic unit (TLU), or linear threshold unit (LTU). Unlike earlier models that used binary inputs and outputs, the TLU deals with numerical values for both. It assigns weights to its inputs, calculates the weighted sum, and then processes this sum through a step function to produce the output.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="pics/perceptron.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Threshold logic unit: an artificial neuron which computes a weighted sum of its inputs then applies a step function</figcaption></figure>
</div>
</section></section><section id="the-perceptron" class="level2" data-number="17.2"><h2 data-number="17.2" class="anchored" data-anchor-id="the-perceptron">
<span class="header-section-number">17.2</span> The Perceptron</h2>
<p>A single Threshold Logic Unit (TLU) performs straightforward linear binary classification by computing a linear combination of inputs. If the result surpasses a certain threshold, it assigns a positive class; otherwise, it assigns a negative class, functioning similarly to Logistic Regression or a linear SVM classifier.</p>
<p>A Perceptron consists of a single layer of TLUs, each connected to all inputs, forming what’s known as a fully connected or dense layer. Input neurons pass their received inputs directly through. Additionally, a bias neuron, always outputting 1, is included to facilitate processing. This setup allows a Perceptron, even with just two inputs, to simultaneously classify into three distinct binary categories, rendering it a multioutput classifier.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="pics/perceptron2.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Architecture of a Perceptron with two input neurons, one bias neuron, and three output neurons.</figcaption></figure>
</div>
<p>The activation function activates artificial neurons in TLUs through a step function, with other types also available, not just step functions. Perceptron training, inspired by Hebb’s rule from his 1949 book, is based on the idea that frequent activation between two biological neurons strengthens their connection, aptly summarized as “Cells that fire together, wire together.” This concept, Hebbian learning, influences Perceptron training, which adjusts connection weights to minimize prediction errors. Training involves processing one instance at a time, adjusting weights for each misprediction to favor inputs leading to correct outcomes.</p>
<p>Unlike Logistic Regression classifiers that provide class probabilities, Perceptrons make predictions using a strict threshold, which sometimes makes Logistic Regression a preferred choice. In 1969, Marvin Minsky and Seymour Papert criticized Perceptrons for their inability to solve simple problems, a disappointment that led some researchers to abandon neural networks for other areas of artificial intelligence. However, this limitation can be overcome by using a network of multiple Perceptrons, known as a Multilayer Perceptron (MLP).</p>
</section><section id="example-iris-data" class="level2" data-number="17.3"><h2 data-number="17.3" class="anchored" data-anchor-id="example-iris-data">
<span class="header-section-number">17.3</span> Example: Iris data</h2>
<p>Let’s illustrate the Perceptron using the Iris dataset. We will first use just one TLU and only focus on the two species setosa and versicolor.</p>
<p>Note in the code how the weights are updated. In a Perceptron, the weights are updated using a simple rule designed to minimize the error in predictions over training iterations. The goal of the Perceptron learning algorithm is to find a set of weights that correctly classifies all training instances.</p>
<p>After making a prediction, the Perceptron checks if the prediction is correct. If the prediction is incorrect, the weights are updated using the rule: <span class="math display">\[
w_{i(new)} = w_{i(old)} + \Delta w_i
\]</span></p>
<p>where <span class="math inline">\(w_{i(new)}\)</span> is the updated weight, <span class="math inline">\(w_{i(old)}\)</span> is the current weight, and <span class="math inline">\(\Delta w_i\)</span> is the change in weight. The change in weight <span class="math inline">\(\Delta w_i\)</span> is calculated as: <span class="math display">\[
\Delta w_i = \eta (y - \hat{y}) x_i
\]</span> Here, <span class="math inline">\(\eta\)</span> is the learning rate (a small positive value that determines the step size of the update), <span class="math inline">\(y\)</span> is the true label, <span class="math inline">\(\hat{y}\)</span> is the predicted label, and <span class="math inline">\(x_i\)</span> is the input feature value. The true label <span class="math inline">\(y\)</span> and the predicted label <span class="math inline">\(\hat{y}\)</span> are usually encoded as 1 for the positive class and -1 for the negative class. If the prediction is correct, there’s no need to update the weights for that particular instance.</p>
<p><strong>Repeat</strong>: This process is repeated for all training instances for a number of epochs or until the algorithm reaches a specified criterion (e.g., a certain number of epochs or a threshold for the minimum number of errors).</p>
<p>The essence of this update rule is simple: if the prediction is correct, do nothing; if the prediction is incorrect, adjust the weights in the direction that would make the correct classification more likely in future predictions. This update mechanism allows the Perceptron to gradually converge towards a solution that separates the classes, provided that the data is linearly separable.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">iris_binary</span> <span class="op">=</span> <span class="va">iris</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'setosa'</span>, <span class="st">'versicolor'</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Species <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/if_else.html">if_else</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">'setosa'</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">perceptron_train</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span>, <span class="va">learning_rate</span> <span class="op">=</span> <span class="fl">0.01</span>, <span class="va">n_iter</span> <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span> <span class="co"># Number of features</span></span>
<span>  <span class="va">weights</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span> <span class="co"># Initialize weights</span></span>
<span>  <span class="va">labels</span> <span class="op">=</span> <span class="va">data</span><span class="op">[</span>,<span class="va">n</span><span class="op">+</span><span class="fl">1</span><span class="op">]</span></span>
<span>  </span>
<span>  <span class="co">#keep track of the number of errors for each iteration</span></span>
<span>  <span class="va">errors</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"numeric"</span>, <span class="va">n_iter</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co">#go through the entire dataset n_iter times</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_iter</span><span class="op">)</span> <span class="op">{</span></span>
<span>    </span>
<span>    <span class="co">#for this iteration, start with no error</span></span>
<span>    <span class="va">error_count</span> <span class="op">=</span> <span class="fl">0</span></span>
<span>    </span>
<span>    <span class="co">#update the weights one observation at a time</span></span>
<span>    <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="co"># Calculate prediction</span></span>
<span>      <span class="va">input</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">data</span><span class="op">[</span><span class="va">j</span>, <span class="fl">1</span><span class="op">:</span><span class="va">n</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="co"># Adding bias input as 1</span></span>
<span>      </span>
<span>      <span class="co">#the step function</span></span>
<span>      <span class="va">prediction</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">input</span> <span class="op">*</span> <span class="va">weights</span><span class="op">)</span> <span class="op">&gt;=</span> <span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span></span>
<span>      </span>
<span>      <span class="co"># Update weights</span></span>
<span>      <span class="va">update</span> <span class="op">=</span> <span class="va">learning_rate</span> <span class="op">*</span> <span class="op">(</span><span class="va">labels</span><span class="op">[</span><span class="va">j</span><span class="op">]</span> <span class="op">-</span> <span class="va">prediction</span><span class="op">)</span></span>
<span>      <span class="va">weights</span> <span class="op">=</span> <span class="va">weights</span> <span class="op">+</span> <span class="va">update</span> <span class="op">*</span> <span class="va">input</span></span>
<span>      </span>
<span>      <span class="co">#check to see if there is an error in the prediction</span></span>
<span>      <span class="va">error_count</span> <span class="op">=</span> <span class="va">error_count</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">update</span> <span class="op">!=</span> <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>    </span>
<span>    <span class="va">errors</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">=</span> <span class="va">error_count</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>weights<span class="op">=</span><span class="va">weights</span>, errors <span class="op">=</span> <span class="va">errors</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co">#train the perceptron</span></span>
<span><span class="va">model</span> <span class="op">=</span> <span class="fu">perceptron_train</span><span class="op">(</span><span class="va">iris_binary</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  0.020  0.022  0.072 -0.104 -0.044</code></pre>
</div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#plot the error made each iteration</span></span>
<span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>iter <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span>, err <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">errors</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">iter</span>, y <span class="op">=</span> <span class="va">err</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Iterations"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Number of misclassifications"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="17_MLP_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="576"></p>
</div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#make predictions based on the trained weights</span></span>
<span><span class="va">perceptron_predict</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">data</span>, <span class="va">weights</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span>  <span class="va">input</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">data</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="op">(</span><span class="va">n</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="op">)</span><span class="co"># Add bias input as 1</span></span>
<span>  <span class="va">prediction</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">input</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="va">weights</span><span class="op">)</span> <span class="op">&gt;=</span> <span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">prediction</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">predictions</span> <span class="op">=</span> <span class="fu">perceptron_predict</span><span class="op">(</span><span class="va">iris_binary</span>, <span class="va">model</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span>Predicted <span class="op">=</span> <span class="va">predictions</span>, Actual <span class="op">=</span> <span class="va">iris_binary</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Actual
Predicted -1  1
       -1 50  0
       1   0 50</code></pre>
</div>
</div>
<p>This code defines a basic Perceptron model and applies it to a subset of the <code>iris</code> dataset, targeting a binary classification problem. The Perceptron function iterates through the dataset, adjusting the weights based on the learning rate. After training, the function returns the final weights and the number of errors per iteration, allowing us to evaluate the model’s performance and learning progress over time.</p>
<p>Note that the perceptron was able to make a perfect prediction. In fact, it only required just a few iterations before it was able to determine the weights to make the predictions with no errors. Remember that we only trained the perceptron on the data with no validation set or testing set. A reason for such great predictions is that the two species setosa and versicolor are clearly separable as seen below</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">iris</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'setosa'</span>, <span class="st">'versicolor'</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Length</span>, y <span class="op">=</span> <span class="va">Petal.Width</span>, color <span class="op">=</span> <span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="17_MLP_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>What if we tried to classify only species versicolor and virginica displayed below?</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">iris</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'virginica'</span>, <span class="st">'versicolor'</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Petal.Length</span>, y <span class="op">=</span> <span class="va">Petal.Width</span>, color <span class="op">=</span> <span class="va">Species</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="17_MLP_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="576"></p>
</div>
</div>
<p>This is not as cleary separable. Let’s see how the perceptron does.</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Load the iris dataset and filter for binary classification</span></span>
<span><span class="va">iris_binary</span> <span class="op">=</span> <span class="va">iris</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">Species</span> <span class="op"><a href="https://rdrr.io/r/base/match.html">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'virginica'</span>, <span class="st">'versicolor'</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Species <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/if_else.html">if_else</a></span><span class="op">(</span><span class="va">Species</span> <span class="op">==</span> <span class="st">'versicolor'</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># will code virginica as a 1 and versicolor as -1</span></span>
<span></span>
<span></span>
<span><span class="co">#train the perceptron</span></span>
<span><span class="va">model</span> <span class="op">=</span> <span class="fu">perceptron_train</span><span class="op">(</span><span class="va">iris_binary</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  0.080  1.104  0.668 -1.410 -1.190</code></pre>
</div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#plot the error made each iteration</span></span>
<span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>iter <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span>, err <span class="op">=</span> <span class="va">model</span><span class="op">$</span><span class="va">errors</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">iter</span>, y <span class="op">=</span> <span class="va">err</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Iterations"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"Number of misclassifications"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="17_MLP_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="576"></p>
</div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#make predictions based on the trained weights</span></span>
<span><span class="va">predictions</span> <span class="op">=</span> <span class="fu">perceptron_predict</span><span class="op">(</span><span class="va">iris_binary</span>, <span class="va">model</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span>Predicted <span class="op">=</span> <span class="va">predictions</span>, Actual <span class="op">=</span> <span class="va">iris_binary</span><span class="op">$</span><span class="va">Species</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Actual
Predicted -1  1
       -1 50  3
       1   0 47</code></pre>
</div>
</div>
<p>First note the plot of the errors, it appears the errors converge to 2 errors per iteration with it jumping to 4 errors occasionally.</p>
<p>At the end, there are three versicolor species that we missclassify as virginica.</p>
<p>Remember, the Perceptron is a fundamental building block of neural networks and is most effective for simple linearly separable datasets. For more complex datasets or multiclass classification, we need to look into more advanced algorithms or use neural networks with multiple layers (Multilayer Perceptrons).</p>
</section><section id="multilayer-perceptron" class="level2" data-number="17.4"><h2 data-number="17.4" class="anchored" data-anchor-id="multilayer-perceptron">
<span class="header-section-number">17.4</span> Multilayer Perceptron</h2>
<p>A Multilayer Perceptron (MLP) consists of an input layer, several hidden layers of TLUs, and a final TLU output layer. The layers nearest the input are called lower layers, while those near the output are upper layers. All layers, except the output, feature a bias neuron and full interconnectivity with the subsequent layer.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="pics/mlp.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Architecture of a Multilayer Perceptron with two inputs, one hidden layer of four neurons, and three output neurons.</figcaption></figure>
</div>
<p>When an MLP includes numerous hidden layers, it’s termed a deep neural network (DNN), the study of which falls under Deep Learning. This term is broadly applied to any neural network-based models, regardless of depth. Despite initial challenges in training MLPs, the introduction of the backpropagation training algorithm by David Rumelhart, Geoffrey Hinton, and Ronald Williams in 1986 marked a significant breakthrough, and it remains in use today.</p>
</section><section id="gradient-descent-and-backpropagation" class="level2" data-number="17.5"><h2 data-number="17.5" class="anchored" data-anchor-id="gradient-descent-and-backpropagation">
<span class="header-section-number">17.5</span> Gradient Descent and Backpropagation</h2>
<p>Gradient descent is like trying to find the lowest point in a valley when you’re standing in thick fog. Imagine you’re at a hilly park but can’t see much around you. You want to get to the lowest point of the park, where there’s a beautiful lake, but because of the fog (or in real life, because we don’t know the exact layout of our problem), you can’t see where the lake is directly.</p>
<p>So, what do you do? You feel the ground beneath your feet to figure out which way is downhill and take a step in that direction, hoping it’ll get you closer to the lake. After you take the step, you feel around again and take another step downhill. You repeat this process, each time moving in the direction that seems to go downhill, until you’re standing right next to the lake, at the lowest point.</p>
<p>In this analogy, the park represents a problem you’re trying to solve with many potential solutions (some good, some not so good), and the lake represents the best solution (the “lowest point”). The process of feeling for the downhill direction is like calculating the gradient, which tells you how to adjust your position to get closer to the best solution. The steps you take are like iterations in the algorithm, gradually improving the solution until it’s good enough or can’t get any better.</p>
<p>Let’s now describe gradient descent using mathematical notation.</p>
<section id="objective-function" class="level4"><h4 class="anchored" data-anchor-id="objective-function">Objective Function</h4>
<p>Suppose you have a function <span class="math inline">\(f(\theta)\)</span> you want to minimize, where <span class="math inline">\(\theta\)</span> represents the parameters (or variables) of the function.</p>
</section><section id="gradient-calculation" class="level4"><h4 class="anchored" data-anchor-id="gradient-calculation">Gradient Calculation</h4>
<p>The gradient of <span class="math inline">\(f\)</span>, denoted as <span class="math inline">\(\nabla f(\theta)\)</span>, is a vector that contains all the partial derivatives of <span class="math inline">\(f\)</span> with respect to each parameter in <span class="math inline">\(\theta\)</span>. The gradient points in the direction of the steepest ascent. Mathematically, if <span class="math inline">\(\theta\)</span> is a two-dimensional vector <span class="math inline">\(\theta = (x, y)\)</span>, then the gradient of <span class="math inline">\(f\)</span> at <span class="math inline">\(\theta\)</span> is:</p>
<p><span class="math display">\[
\nabla f(\theta) = \left( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} \right)
\]</span></p>
</section><section id="gradient-descent-step" class="level4"><h4 class="anchored" data-anchor-id="gradient-descent-step">Gradient Descent Step</h4>
<p>To minimize <span class="math inline">\(f\)</span>, you want to go in the opposite direction of the gradient because that’s the direction of the steepest descent. So, you update <span class="math inline">\(\theta\)</span> by taking a step opposite to the gradient:</p>
<p><span class="math display">\[
\theta_{\text{new}} = \theta - \alpha \nabla f(\theta)
\]</span></p>
<p>Here, <span class="math inline">\(\alpha\)</span> is the learning rate, a small positive number that controls the size of the step. Choosing a good value for <span class="math inline">\(\alpha\)</span> is crucial: too small, and the algorithm will converge slowly; too large, and it may overshoot the minimum or even diverge.</p>
</section><section id="iterative-process" class="level4"><h4 class="anchored" data-anchor-id="iterative-process">Iterative Process</h4>
<p>You repeat this update process iteratively:</p>
<ol type="1">
<li>Calculate the gradient of the current <span class="math inline">\(\theta\)</span>.</li>
<li>Update <span class="math inline">\(\theta\)</span> by taking a step in the direction opposite to the gradient.</li>
<li>Repeat until the change in <span class="math inline">\(f(\theta)\)</span> is smaller than a predefined threshold (indicating convergence) or until you reach a maximum number of iterations.</li>
</ol>
<p>The iterative process can be summarized by the formula repeated for <span class="math inline">\(k = 1, 2, 3, \ldots\)</span>, until convergence:</p>
<p><span class="math display">\[
\theta^{(k+1)} = \theta^{(k)} - \alpha \nabla f(\theta^{(k)})
\]</span></p>
<p>This process gradually adjusts <span class="math inline">\(\theta\)</span> to find the minimum value of <span class="math inline">\(f(\theta)\)</span>, optimizing the parameters of your model.</p>
</section><section id="backpropagation" class="level3" data-number="17.5.1"><h3 data-number="17.5.1" class="anchored" data-anchor-id="backpropagation">
<span class="header-section-number">17.5.1</span> Backpropagation</h3>
<p>Backpropagation, short for “backward propagation of errors,” is a core algorithm in the field of neural networks, enabling them to learn from observational data. It’s essentially a method for calculating the gradient (the direction and rate of change) of the loss function (which measures the difference between the predicted output and the actual output) with respect to each weight in the network. This gradient is then used by optimization algorithms like gradient descent to adjust the weights in a direction that minimizes the loss. Here’s how backpropagation works:</p>
<section id="forward-pass" class="level4"><h4 class="anchored" data-anchor-id="forward-pass">Forward Pass</h4>
<ol type="1">
<li>
<strong>Input Forwarding:</strong> The process begins by passing an input through the neural network, layer by layer, until the output layer produces its prediction.</li>
<li>
<strong>Loss Calculation:</strong> The difference between the predicted output and the actual output (the ground truth) is calculated using a loss function.</li>
</ol></section><section id="backward-pass" class="level4"><h4 class="anchored" data-anchor-id="backward-pass">Backward Pass</h4>
<ol start="3" type="1">
<li>
<strong>Local Gradients Calculation:</strong> Starting at the output layer, backpropagation calculates the gradient of the loss function with respect to each weight by applying the chain rule of calculus. This tells us how much a change in a weight would change the loss.</li>
<li>
<strong>Error Propagation Backwards:</strong> This gradient calculation and error attribution process is performed layer by layer, moving backward from the output layer to the input layer. At each layer, the algorithm calculates how much each neuron’s output contributed to the error in the layers below.</li>
</ol></section><section id="weight-update" class="level4"><h4 class="anchored" data-anchor-id="weight-update">Weight Update</h4>
<ol start="5" type="1">
<li>
<strong>Gradient Descent Application:</strong> With the gradients computed, gradient descent is then applied to adjust the weights. Each weight is updated in the direction that most reduces the loss, based on its gradient. The size of the step taken in this direction is determined by the learning rate.</li>
</ol></section><section id="iteration" class="level4"><h4 class="anchored" data-anchor-id="iteration">Iteration</h4>
<ol start="6" type="1">
<li>
<strong>Iterate:</strong> This entire process is repeated for many iterations (forward pass, backward pass, weight update) across all the samples in the training data, often in small batches. With each iteration, the network weights are adjusted to minimize the loss, improving the model’s predictions.</li>
</ol></section><section id="relationship-between-backpropagation-and-gradient-descent" class="level4"><h4 class="anchored" data-anchor-id="relationship-between-backpropagation-and-gradient-descent">Relationship Between Backpropagation and Gradient Descent</h4>
<p>Backpropagation and gradient descent are connected. Backpropagation is the mechanism by which gradients are calculated efficiently for each weight in the network, taking into account the complex, interconnected structure of the neural network. Gradient descent is the optimization technique that uses these gradients to adjust the weights, aiming to minimize the loss function.</p>
<p>In summary, backpropagation computes the necessary information (gradients) to understand how to adjust neural network weights to reduce errors, while gradient descent is the strategy used to make those adjustments, leveraging the information provided by backpropagation.</p>
<p>Let’s delve into the specifics of the backpropagation algorithm:</p>
<ul>
<li>It processes one small group of training instances at a time, known as a mini-batch (for instance, with 32 samples in each), cycling through the entire dataset multiple times. Each complete cycle is referred to as an epoch.</li>
<li>For each mini-batch, the process begins by feeding the data into the network’s input layer, which forwards it to the subsequent hidden layer. The algorithm calculates the outputs for all neurons in that layer for every sample in the mini-batch. These outputs are then relayed to the following layer, and this sequence continues until the final layer’s output is obtained. This sequence of operations is known as the forward pass, which resembles the prediction process but with the intermediate results being saved for later use in the backward pass.</li>
<li>The algorithm next evaluates the discrepancy between the network’s actual output and the intended output, utilizing a loss function to quantify the error.</li>
<li>It then determines the contribution of each output connection to the overall error, applying the chain rule—a crucial concept in calculus—to achieve a quick and precise calculation. Following this, it assesses the error contributions from each connection in the preceding layer, progressively working its way back to the input layer. This backward journey effectively calculates the error gradient across all the network’s connections by propagating the error gradient in reverse, which is why this technique is called backpropagation.</li>
<li>The final step involves adjusting the connection weights within the network through Gradient Descent, guided by the error gradients calculated in the previous step.</li>
</ul>
<p>The backpropagation algorithm is pivotal because it systematically makes a prediction (forward pass), evaluates the prediction error, assesses the error contribution from each connection by moving in reverse through the layers (reverse pass), and adjusts the connection weights to minimize the error (Gradient Descent step).</p>
</section></section></section><section id="activation-functions" class="level2" data-number="17.6"><h2 data-number="17.6" class="anchored" data-anchor-id="activation-functions">
<span class="header-section-number">17.6</span> Activation Functions</h2>
<p>To ensure the effectiveness of the backpropagation algorithm, its developers introduced a crucial modification to the architecture of the MLP: they substituted the step function with the logistic (sigmoid) function, defined as <span class="math display">\[
\sigma(z) = \frac{1} {1 + \exp(–z)}
\]</span> This substitution was critical because the step function consists of flat segments that provide no gradient for Gradient Descent to utilize (since Gradient Descent requires a slope to move), whereas the logistic function possesses a consistent, nonzero derivative across its domain, facilitating progress in Gradient Descent at each step. Moreover, the algorithm is compatible with various activation functions beyond the logistic function. Two additional widespread options include:</p>
<ul>
<li>The hyperbolic tangent function (tanh): <span class="math inline">\(\tanh(z) = 2\sigma(2z) – 1\)</span>. Similar to the logistic function, the tanh function is S-shaped, continuous, and differentiable, offering an output range between –1 and 1, as opposed to the logistic function’s 0 to 1. This characteristic often leads to a more centered output distribution from each layer at the start of training, which can accelerate the convergence process.</li>
<li>The Rectified Linear Unit function (ReLU): <span class="math inline">\(ReLU(z) = \max(0, z)\)</span>. The ReLU function is continuous but has a non-differentiable point at z = 0, where the slope changes abruptly, potentially causing issues with Gradient Descent. Despite this, ReLU is highly effective in practice, primarily due to its computational efficiency and because it does not have an upper limit on its output, which mitigates certain problems during Gradient Descent.</li>
</ul>
<p>These activation functions are valuable because linear transformations alone, when stacked, result in another linear transformation, offering no advantage over a single-layer model. This means that without incorporating nonlinearities between layers, a deep network would not differ from a shallow one, severely limiting its problem-solving capabilities. However, a sufficiently large Deep Neural Network (DNN) with nonlinear activation functions has the theoretical potential to approximate any continuous function, highlighting the importance of these nonlinearities in complex problem-solving.</p>


</section></main><!-- /main --><script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  var t = document.getElementsByClassName("webex-total_correct");
  for (var i = 0; i < t.length; i++) {
    p = t[i].parentElement;
    var correct = p.getElementsByClassName("webex-correct").length;
    var solvemes = p.getElementsByClassName("webex-solveme").length;
    var radiogroups = p.getElementsByClassName("webex-radiogroup").length;
    var selects = p.getElementsByClassName("webex-select").length;

    t[i].innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* check answers */
check_func = function() {
  console.log("webex: check answers");

  var cl = this.parentElement.classList;
  if (cl.contains('unchecked')) {
    cl.remove("unchecked");
    this.innerHTML = "Hide Answers";
  } else {
    cl.add("unchecked");
    this.innerHTML = "Show Answers";
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  var check_sections = document.getElementsByClassName("webex-check");
  console.log("check:", check_sections.length);
  for (var i = 0; i < check_sections.length; i++) {
    check_sections[i].classList.add("unchecked");

    let btn = document.createElement("button");
    btn.innerHTML = "Show Answers";
    btn.classList.add("webex-check-button");
    btn.onclick = check_func;
    check_sections[i].appendChild(btn);

    let spn = document.createElement("span");
    spn.classList.add("webex-total_correct");
    check_sections[i].appendChild(spn);
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    solveme[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    selects[i].insertAdjacentHTML("afterend", " <span class='webex-icon'></span>")
  }

  update_total_correct();
}

</script><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./16_DBSCAN.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">DBSCAN</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./18_Fitting.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Fitting and Overfitting</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">STA 3311</div>
  </div>
</footer>


</body></html>