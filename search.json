[
  {
    "objectID": "18_Fitting.html#introduction",
    "href": "18_Fitting.html#introduction",
    "title": "18  Fitting and Overfitting",
    "section": "18.1 Introduction",
    "text": "18.1 Introduction\nIn machine learning, the terms ‘overfitting’ and ‘underfitting’ describe two common pitfalls that can hinder the performance of a model when making predictions on new, unseen data. These concepts are foundational in understanding model performance and optimizing algorithms for practical use.\n\nDefinition of Overfitting: Overfitting occurs when a model learns the training data too well, to the extent that it captures noise and outliers as if they were representative of the underlying pattern. This results in a model that performs very well on its training data but poorly on any new or unseen data because it has essentially memorized the data rather than learned to generalize from it. Overfitting is akin to learning the quirks of a particular set of data so well that the model fails to make correct predictions on data that does not share those same quirks.\nDefinition of Underfitting: Conversely, underfitting happens when a model is too simple to capture the underlying structure of the data. This simplicity can result from having too few parameters in the model (underparameterization), which prevents it from learning enough about the data. As a result, such a model will perform poorly not only on new data but also on its training data, indicating that it has not captured the basic trends or patterns.\nThe Importance of Balance: The ultimate goal in model training is to achieve a balance between overfitting and underfitting. This balance ensures that the model captures the true underlying patterns of the data, with enough flexibility to perform well on new, unseen data but without being swayed by random fluctuations or outliers in the training set. Achieving this balance often involves techniques such as model selection, regularization, and validation."
  },
  {
    "objectID": "18_Fitting.html#understanding-fitting-in-machine-learning",
    "href": "18_Fitting.html#understanding-fitting-in-machine-learning",
    "title": "18  Fitting and Overfitting",
    "section": "18.2 Understanding Fitting in Machine Learning",
    "text": "18.2 Understanding Fitting in Machine Learning\n\nTraining Set\nThe training set is the primary dataset on which a machine learning model is built. It’s used to fit the model parameters and is crucial for learning the relationships and patterns in the data. The model adjusts its weights based on the error it makes predictions on this set. However, using only a training set can lead to overfitting, especially if the model is overly complex and the training data contains noise or outliers. The model may perform exceptionally well on the training set but poorly on any unseen data because it has learned the specific quirks and noise of the training data instead of the general underlying patterns.\n\n\nValidation Set\nTo mitigate the risk of overfitting, a validation set is used. This dataset is separate from the training set and is used to evaluate the model performance during the training phase. By assessing the model on the validation set, one can tune the model’s hyperparameters (like the number of layers in a neural network or the parameters in regularization techniques) more effectively. The validation set helps in deciding when to stop training the model—a method known as early stopping—to ensure that the model generalizes well and does not continue to learn the noise in the training set.\n\n\nTest Set\nAfter a model has been trained and validated, the final step is to evaluate its performance on a test set. This dataset is never used during the training phase and acts as a new, unseen dataset for the model. The performance on the test set provides a realistic evaluation of how well the model will perform in the real world, on entirely new data. This is the ultimate test of generalization and is critical for understanding the effectiveness of the machine learning model.\nUsing these three types of datasets—training, validation, and test—helps in effectively training, tuning, and evaluating a machine learning model. This approach ensures that the model not only learns the underlying patterns from the training data but also generalizes well to new, unseen data, thus balancing overfitting and underfitting. These practices are fundamental to building robust and effective machine learning systems that perform well in practical applications."
  },
  {
    "objectID": "18_Fitting.html#techniques-to-combat-overfitting",
    "href": "18_Fitting.html#techniques-to-combat-overfitting",
    "title": "18  Fitting and Overfitting",
    "section": "18.3 Techniques to Combat Overfitting",
    "text": "18.3 Techniques to Combat Overfitting\n\n18.3.1 Regularization\nRegularization serves as a technique to impose constraints on the quantity and type of information your model can store. If a model can only afford to store information that improves its performance on the test data, it is less likely to fit to idiosyncratic, noisy features of the training data.\nL1 Regularization (Lasso)\nL1 regularization adds a penalty equal to the absolute value of the magnitude of the coefficients. This type of regularization can lead to sparse models with few coefficients; some coefficients can become zero and eliminated from the model. This feature makes L1 regularization useful not only for preventing overfitting but also for feature selection.\nL2 Regularization (Ridge)\nL2 regularization adds a penalty equal to the square of the magnitude of the coefficients. Unlike L1, L2 regularization does not result in sparse models and usually leads to smaller coefficients that are distributed more equally. L2 is effective at handling collinearity (high correlations among features) and controlling model complexity by keeping the coefficients small.\n\nWhen to Use Each\n\nL1 Regularization: When you have a large number of features and expect only a few of them to be important, L1 can help you increase model interpretability by keeping only the most significant features.\nL2 Regularization: When model simplicity and prediction accuracy are paramount, and you have data with complex feature relationships.\n\n\n\nCombining L1 and L2 Regularization (Elastic Net)\nSometimes, a combination of L1 and L2 regularization (known as Elastic Net) is used, which merges the penalties of L1 and L2 regularization. This method is particularly effective when there are correlations between parameters or when you have more features than training instances.\n\n\n\n18.3.2 Dropout\nDropout is a powerful and simple regularization method that has been widely used in deep learning. The fundamental idea behind dropout is to randomly “drop” or deactivate a subset of neurons in a neural network during the training process. This randomness helps prevent the neurons from co-adapting too much and relying on the presence of specific other neurons to correct their mistakes, which can lead to overfitting.\n\nHow Dropout Works\nIn dropout, during each training step, each neuron (including input neurons but typically excluding output neurons) has a probability \\(p\\) of being temporarily “dropped out,” meaning it is completely ignored during this step, but it may be active during the next step. The probability \\(p\\) is called the dropout rate, and it’s a hyperparameter that can be tuned. Common values are 0.2 to 0.5. This randomness introduces noise into the output of a layer, simulating the effect of training many different networks. At test time, no neurons are dropped out. Instead, their outputs are adjusted by a factor equal to the dropout rate to balance the larger number of active units during training.\n\n\nBenefits of Dropout\n\nReduces Overfitting: Dropout prevents units from co-adapting too closely. By dropping different sets of neurons, it ensures that the network does not rely on any single neuron for correct output. This reduces the risk of overfitting on the training data.\nApproximates Training Many Models: Each iteration with a different set of neurons dropped can be seen as training a different neural network. At test time, using the unthinned network is akin to averaging the predictions of all these thinned networks.\nCost-effective Ensemble Technique: While training numerous models in an ensemble can be computationally expensive, dropout provides a cheaper and more resource-efficient approximation to this process.\n\n\n\nConsiderations When Using Dropout\n\nChoosing the Right Dropout Rate: The dropout rate is a hyperparameter that can significantly affect the performance of a model. It often requires tuning using a validation set or using hyperparameter optimization techniques.\nImpact on Training Time: Because dropout involves only a subset of neurons during each training step, it can sometimes require a longer training period to converge.\nUse with Other Regularization Techniques: Dropout can be effectively combined with other regularization techniques like L1 and L2 regularization to further enhance the generalization ability of the model.\n\nBy implementing dropout correctly, you can significantly improve the robustness and generalization of deep learning models, especially in complex tasks where overfitting is a significant concern."
  },
  {
    "objectID": "18_Fitting.html#hyperparameter-tuning",
    "href": "18_Fitting.html#hyperparameter-tuning",
    "title": "18  Fitting and Overfitting",
    "section": "18.4 Hyperparameter Tuning",
    "text": "18.4 Hyperparameter Tuning\n\nGrid Search\nGrid search is the most straightforward approach to hyperparameter tuning. It involves specifying a grid of all possible combinations of hyperparameters and evaluating the model’s performance for each combination. This method is exhaustive and ensures that the best combination is selected. However, grid search can be computationally expensive, especially when the hyperparameter space is large or when the model evaluation is time-consuming.\n\n\nRandom Search\nRandom search improves over grid search by selecting random combinations of the hyperparameters to evaluate. While this method does not guarantee finding the best combination as grid search does, it is more efficient, especially in high-dimensional spaces where it’s unlikely that the best hyperparameters lie on a grid. Random search can often find a good combination much faster than grid search.\n\n\nBayesian Optimization\nBayesian optimization is a mor e sophisticated method that models the hyperparameter tuning process as a Bayesian inference problem. It builds a probabilistic model of the function mapping from hyperparameter values to the target evaluated metric. The algorithm then uses this model to make intelligent decisions about which hyperparameters to evaluate next. This method is particularly useful when evaluations of the model are expensive, as it significantly reduces the number of trials needed to find a good set of hyperparameters.\n\n\nGradient-based Optimization\nSome newer techniques involve using gradient information to optimize hyperparameters. This approach is typically used when hyperparameters are continuous and differentiable, allowing the optimization process to leverage gradients to more quickly converge to optimal values. This method can be very efficient but is dependent on the availability of gradients."
  },
  {
    "objectID": "18_Fitting.html#stopping-rules",
    "href": "18_Fitting.html#stopping-rules",
    "title": "18  Fitting and Overfitting",
    "section": "18.5 Stopping Rules",
    "text": "18.5 Stopping Rules\nStopping rules in machine learning are criteria or methods used to decide when to halt the training process of an algorithm. The primary aim of these rules is to ensure that a model does not overtrain on the dataset, which can lead to overfitting. Overfitting occurs when a model learns the training data too well, including its noise and outliers, making it perform poorly on unseen data.\n\n18.5.1 Early Stopping:\nOne of the most common stopping rules is early stopping. This method involves monitoring the model’s performance on a validation set at each epoch (i.e., a full iteration over the entire training dataset). If the model’s performance on the validation set starts to degrade, or fails to improve for a predefined number of consecutive epochs, the training is halted. The logic behind early stopping is that the model’s ability to generalize (perform well on unseen data) starts to decline after a certain point as it begins to memorize the training data rather than learning to generalize from it.\n\nHow Early Stopping Works\n\nMonitoring Metric: Typically, a performance metric such as validation loss is monitored.\nPatience: This is a hyperparameter that defines the number of epochs to wait before stopping, after the metric has stopped improving. This parameter is crucial as it prevents the model from stopping too early and allows some room for potential recovery in model performance.\nRestore Best Weights: Often, the configuration of the model weights that achieved the best performance on the validation set is restored at the end of training. This ensures that the model does not retain overfitted weights.\n\n\n\nBenefits of Early Stopping\n\nPrevents Overfitting: By halting the training process before the model starts to overfit, early stopping helps maintain the model’s generalizability.\nSaves Resources: Early stopping can reduce computational costs by reducing the number of epochs for which the model needs to be trained.\nImproves Experimentation: Reduces the time to experiment with different model architectures and hyperparameters since each experiment runs only as long as it remains productive.\n\nImplementing effective stopping rules such as early stopping is crucial for developing robust machine learning models that generalize well to new, unseen data. By judiciously choosing when to halt the training process, practitioners can avoid the pitfalls of overfitting while optimizing the computational efficiency of their model training processes."
  },
  {
    "objectID": "18_Fitting.html#conclusion",
    "href": "18_Fitting.html#conclusion",
    "title": "18  Fitting and Overfitting",
    "section": "18.6 Conclusion",
    "text": "18.6 Conclusion\nTechniques and methodologies such as regularization (both L1 and L2), dropout, and hyperparameter tuning through methods like grid search, random search, and Bayesian optimization provide a toolbox for machine learning practitioners to refine their models’ performance. These methods not only enhance the predictability and stability of the models but also ensure that they remain practical and efficient across various datasets and under different conditions.\nMoreover, the incorporation of early stopping as a practical approach in training workflows exemplifies the evolving strategies in machine learning that prioritize computational efficiency and model efficacy. The ability to halt training at an optimal point saves resources and protects the model from overlearning and potential degradation in performance on new data.\nIn conclusion, the combination of these techniques represents a comprehensive approach towards building, tuning, and deploying machine learning models that are not only accurate but also resilient and adaptable. As the field continues to evolve, these strategies will undoubtedly be refined, and new techniques will emerge, further enhancing the capability of machine learning models to learn effectively and efficiently."
  }
]